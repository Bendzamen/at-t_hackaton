{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "GoogleGenerativeAIModel",
            "id": "GoogleGenerativeAIModel-2RGCP",
            "name": "model_output",
            "output_types": [
              "LanguageModel"
            ]
          },
          "targetHandle": {
            "fieldName": "llm",
            "id": "ToolCallingAgent-ol8GM",
            "inputTypes": [
              "LanguageModel"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__GoogleGenerativeAIModel-2RGCP{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-2RGCPœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-ol8GM{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "GoogleGenerativeAIModel-2RGCP",
        "sourceHandle": "{œdataTypeœ:œGoogleGenerativeAIModelœ,œidœ:œGoogleGenerativeAIModel-2RGCPœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
        "target": "ToolCallingAgent-ol8GM",
        "targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "APIRequest",
            "id": "APIRequest-mdLsg",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-ol8GM",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__APIRequest-mdLsg{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-mdLsgœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-ol8GM{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "APIRequest-mdLsg",
        "sourceHandle": "{œdataTypeœ:œAPIRequestœ,œidœ:œAPIRequest-mdLsgœ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "ToolCallingAgent-ol8GM",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DuckDuckGoSearchComponent",
            "id": "DuckDuckGoSearchComponent-AjgK2",
            "name": "component_as_tool",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-ol8GM",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__DuckDuckGoSearchComponent-AjgK2{œdataTypeœ:œDuckDuckGoSearchComponentœ,œidœ:œDuckDuckGoSearchComponent-AjgK2œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-ol8GM{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "DuckDuckGoSearchComponent-AjgK2",
        "sourceHandle": "{œdataTypeœ:œDuckDuckGoSearchComponentœ,œidœ:œDuckDuckGoSearchComponent-AjgK2œ,œnameœ:œcomponent_as_toolœ,œoutput_typesœ:[œToolœ]}",
        "target": "ToolCallingAgent-ol8GM",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-CXSsy",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "ToolCallingAgent-ol8GM",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-CXSsy{œdataTypeœ:œTextInputœ,œidœ:œTextInput-CXSsyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-ol8GM{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-CXSsy",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-CXSsyœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "ToolCallingAgent-ol8GM",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "WorkspaceToolsAll",
            "id": "WorkspaceToolsAll-lvXOD",
            "name": "tools_list",
            "output_types": [
              "Tool"
            ]
          },
          "targetHandle": {
            "fieldName": "tools",
            "id": "ToolCallingAgent-ol8GM",
            "inputTypes": [
              "Tool"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__WorkspaceToolsAll-lvXOD{œdataTypeœ:œWorkspaceToolsAllœ,œidœ:œWorkspaceToolsAll-lvXODœ,œnameœ:œtools_listœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-ol8GM{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "WorkspaceToolsAll-lvXOD",
        "sourceHandle": "{œdataTypeœ:œWorkspaceToolsAllœ,œidœ:œWorkspaceToolsAll-lvXODœ,œnameœ:œtools_listœ,œoutput_typesœ:[œToolœ]}",
        "target": "ToolCallingAgent-ol8GM",
        "targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-ol8GMœ,œinputTypesœ:[œToolœ],œtypeœ:œotherœ}"
      },
      {
        "data": {
          "sourceHandle": {
            "dataType": "ToolCallingAgent",
            "id": "ToolCallingAgent-ol8GM",
            "name": "response",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-hDEjR",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ToolCallingAgent-ol8GM{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-ol8GMœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-TextOutput-hDEjR{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-hDEjRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "source": "ToolCallingAgent-ol8GM",
        "sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-ol8GMœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-hDEjR",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-hDEjRœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "ToolCallingAgent-ol8GM",
          "node": {
            "base_classes": [
              "AgentExecutor",
              "Message"
            ],
            "beta": false,
            "category": "langchain_utilities",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "An agent designed to utilize various tools seamlessly within workflows.",
            "display_name": "Tool Calling Agent",
            "documentation": "",
            "edited": false,
            "field_order": [
              "tools",
              "input_value",
              "handle_parsing_errors",
              "verbose",
              "max_iterations",
              "agent_description",
              "llm",
              "system_prompt",
              "chat_history"
            ],
            "frozen": false,
            "icon": "LangChain",
            "key": "ToolCallingAgent",
            "legacy": false,
            "lf_version": "1.6.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Agent",
                "group_outputs": false,
                "hidden": true,
                "method": "build_agent",
                "name": "agent",
                "selected": "AgentExecutor",
                "tool_mode": false,
                "types": [
                  "AgentExecutor"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Response",
                "group_outputs": false,
                "method": "message_response",
                "name": "response",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.01857804455091699,
            "template": {
              "_type": "Component",
              "agent_description": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Agent Description [Deprecated]",
                "dynamic": false,
                "info": "The description of the agent. This is only used when in Tool Mode. Defaults to 'A helpful assistant with access to the following tools:' and tools are added dynamically. This feature is deprecated and will be removed in future versions.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "agent_description",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "A helpful assistant with access to the following tools:"
              },
              "chat_history": {
                "_input_type": "DataInput",
                "advanced": true,
                "display_name": "Chat Memory",
                "dynamic": false,
                "info": "This input stores the chat history, allowing the agent to remember previous conversations.",
                "input_types": [
                  "Data"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "chat_history",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs.inputs import (\n    DataInput,\n    HandleInput,\n    MessageTextInput,\n)\nfrom langflow.schema.data import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"An agent designed to utilize various tools seamlessly within workflows.\"\n    icon = \"LangChain\"\n    name = \"ToolCallingAgent\"\n\n    inputs = [\n        *LCToolsAgentComponent._base_inputs,\n        HandleInput(\n            name=\"llm\",\n            display_name=\"Language Model\",\n            input_types=[\"LanguageModel\"],\n            required=True,\n            info=\"Language model that the agent utilizes to perform tasks effectively.\",\n        ),\n        MessageTextInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt to guide the agent's behavior.\",\n            value=\"You are a helpful assistant that can use tools to answer questions and perform tasks.\",\n        ),\n        DataInput(\n            name=\"chat_history\",\n            display_name=\"Chat Memory\",\n            is_list=True,\n            advanced=True,\n            info=\"This input stores the chat history, allowing the agent to remember previous conversations.\",\n        ),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        messages = [\n            (\"system\", \"{system_prompt}\"),\n            (\"placeholder\", \"{chat_history}\"),\n            (\"human\", \"{input}\"),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        self.validate_tool_names()\n        try:\n            return create_tool_calling_agent(self.llm, self.tools or [], prompt)\n        except NotImplementedError as e:\n            message = f\"{self.display_name} does not support tool calling. Please try using a compatible model.\"\n            raise NotImplementedError(message) from e\n"
              },
              "handle_parsing_errors": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Handle Parse Errors",
                "dynamic": false,
                "info": "Should the Agent fix errors when reading user input for better processing?",
                "list": false,
                "list_add_label": "Add More",
                "name": "handle_parsing_errors",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input provided by the user for the agent to process.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "llm": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Language Model",
                "dynamic": false,
                "info": "Language model that the agent utilizes to perform tasks effectively.",
                "input_types": [
                  "LanguageModel"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "llm",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of attempts the agent can make to complete its task before it stops.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 50
              },
              "system_prompt": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "System Prompt",
                "dynamic": false,
                "info": "System prompt to guide the agent's behavior.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "system_prompt",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a very skilled programmer with 10+ experience in various fields of programming (web apps, static web). You have obtained detailed technical description of a project you should program. Moreover, you have tools you can use.  1. You should create a docker compose file and program all the corresponding services in the root directory (database, frontend, backend...) that will together perform the desired task specified in the technical description. Use the recommended framework from the specification.  2. After you are sure you have implemented all the necessary functionalities, build and run the docker compose. If the build or runtime fails, look at the reasons in the logs, and try to fix it. Until the docker cannot be build, iterate through the code.  When the docker builds correctly and the service is running, return success message, command how to run the app and the localhost web service url after running the app in json format like this   {      \"success\": True      \"run command\": <run command with whole relative path>      \"web service url\": <url to the web service after running the app>   }  If you could not fix the code, return fail message with an error message in json format like this:   {      \"success\": False,      \"error\": <error message>   }  Do not write any other description message except the return json, write the description inside markdown file inside the project. Do not use system default ports such as 5000 or 7000 for web services.IMPORTANT FILE ORGANIZATION RULES: - Always create new projects in /app/workspace/<project-name>/ directory - Use the project name from the user's request as the folder name - Example: If user asks to build \"snake-game\", create it in /app/workspace/snake-game/ - Use list_directory tool first to check if the project folder exists - Create proper project structure with all necessary files (README.md, requirements.txt, etc.)  When starting a new project: 1. Ask the user for the project name if not clear 2. Use shell_command tool: mkdir -p /app/workspace/<project-name> 3. Create all project files inside this directory 4. Provide the user with the path: ./workspace/<project-name>"
              },
              "tools": {
                "_input_type": "HandleInput",
                "advanced": false,
                "display_name": "Tools",
                "dynamic": false,
                "info": "These are the tools that the agent can use to help with tasks.",
                "input_types": [
                  "Tool"
                ],
                "list": true,
                "list_add_label": "Add More",
                "name": "tools",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "verbose": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Verbose",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "verbose",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              }
            },
            "tool_mode": false
          },
          "selected_output": "agent",
          "showNode": true,
          "type": "ToolCallingAgent"
        },
        "dragging": false,
        "id": "ToolCallingAgent-ol8GM",
        "measured": {
          "height": 433,
          "width": 320
        },
        "position": {
          "x": 357.5629788559186,
          "y": 50.25600764579845
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "GoogleGenerativeAIModel-2RGCP",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "category": "google",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Generate text using Google Generative AI.",
            "display_name": "Google Generative AI",
            "documentation": "",
            "edited": false,
            "field_order": [
              "input_value",
              "system_message",
              "stream",
              "max_output_tokens",
              "model_name",
              "api_key",
              "top_p",
              "temperature",
              "n",
              "top_k",
              "tool_model_enabled"
            ],
            "frozen": false,
            "icon": "GoogleGenerativeAI",
            "key": "GoogleGenerativeAIModel",
            "last_updated": "2025-11-07T16:02:55.636Z",
            "legacy": false,
            "lf_version": "1.6.5",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.00000963430161181485,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "Google API Key",
                "dynamic": false,
                "info": "The Google API Key to use for the Google Generative AI.",
                "input_types": [],
                "load_from_db": true,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": true,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\n\nimport requests\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs.inputs import BoolInput, DropdownInput, FloatInput, IntInput, SecretStrInput, SliderInput\nfrom langflow.logging.logger import logger\nfrom langflow.schema.dotdict import dotdict\n\n\nclass GoogleGenerativeAIComponent(LCModelComponent):\n    display_name = \"Google Generative AI\"\n    description = \"Generate text using Google Generative AI.\"\n    icon = \"GoogleGenerativeAI\"\n    name = \"GoogleGenerativeAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_output_tokens\", display_name=\"Max Output Tokens\", info=\"The maximum number of tokens to generate.\"\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model\",\n            info=\"The name of the model to use.\",\n            options=GOOGLE_GENERATIVE_AI_MODELS,\n            value=\"gemini-1.5-pro\",\n            refresh_button=True,\n            combobox=True,\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"Google API Key\",\n            info=\"The Google API Key to use for the Google Generative AI.\",\n            required=True,\n            real_time_refresh=True,\n        ),\n        FloatInput(\n            name=\"top_p\",\n            display_name=\"Top P\",\n            info=\"The maximum cumulative probability of tokens to consider when sampling.\",\n            advanced=True,\n        ),\n        SliderInput(\n            name=\"temperature\",\n            display_name=\"Temperature\",\n            value=0.1,\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\n            info=\"Controls randomness. Lower values are more deterministic, higher values are more creative.\",\n        ),\n        IntInput(\n            name=\"n\",\n            display_name=\"N\",\n            info=\"Number of chat completions to generate for each prompt. \"\n            \"Note that the API may not return the full n completions if duplicates are generated.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"top_k\",\n            display_name=\"Top K\",\n            info=\"Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"tool_model_enabled\",\n            display_name=\"Tool Model Enabled\",\n            info=\"Whether to use the tool model.\",\n            value=False,\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_google_genai import ChatGoogleGenerativeAI\n        except ImportError as e:\n            msg = \"The 'langchain_google_genai' package is required to use the Google Generative AI model.\"\n            raise ImportError(msg) from e\n\n        google_api_key = self.api_key\n        model = self.model_name\n        max_output_tokens = self.max_output_tokens\n        temperature = self.temperature\n        top_k = self.top_k\n        top_p = self.top_p\n        n = self.n\n\n        return ChatGoogleGenerativeAI(\n            model=model,\n            max_output_tokens=max_output_tokens or None,\n            temperature=temperature,\n            top_k=top_k or None,\n            top_p=top_p or None,\n            n=n or 1,\n            google_api_key=SecretStr(google_api_key).get_secret_value(),\n        )\n\n    def get_models(self, *, tool_model_enabled: bool | None = None) -> list[str]:\n        try:\n            import google.generativeai as genai\n\n            genai.configure(api_key=self.api_key)\n            model_ids = [\n                model.name.replace(\"models/\", \"\")\n                for model in genai.list_models()\n                if \"generateContent\" in model.supported_generation_methods\n            ]\n            model_ids.sort(reverse=True)\n        except (ImportError, ValueError) as e:\n            logger.exception(f\"Error getting model names: {e}\")\n            model_ids = GOOGLE_GENERATIVE_AI_MODELS\n        if tool_model_enabled:\n            try:\n                from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n            except ImportError as e:\n                msg = \"langchain_google_genai is not installed.\"\n                raise ImportError(msg) from e\n            for model in model_ids:\n                model_with_tool = ChatGoogleGenerativeAI(\n                    model=self.model_name,\n                    google_api_key=self.api_key,\n                )\n                if not self.supports_tool_calling(model_with_tool):\n                    model_ids.remove(model)\n        return model_ids\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None):\n        if field_name in {\"base_url\", \"model_name\", \"tool_model_enabled\", \"api_key\"} and field_value:\n            try:\n                if len(self.api_key) == 0:\n                    ids = GOOGLE_GENERATIVE_AI_MODELS\n                else:\n                    try:\n                        ids = self.get_models(tool_model_enabled=self.tool_model_enabled)\n                    except (ImportError, ValueError, requests.exceptions.RequestException) as e:\n                        logger.exception(f\"Error getting model names: {e}\")\n                        ids = GOOGLE_GENERATIVE_AI_MODELS\n                build_config.setdefault(\"model_name\", {})\n                build_config[\"model_name\"][\"options\"] = ids\n                build_config[\"model_name\"].setdefault(\"value\", ids[0])\n            except Exception as e:\n                msg = f\"Error getting model names: {e}\"\n                raise ValueError(msg) from e\n        return build_config\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_output_tokens": {
                "_input_type": "IntInput",
                "advanced": false,
                "display_name": "Max Output Tokens",
                "dynamic": false,
                "info": "The maximum number of tokens to generate.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_output_tokens",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": true,
                "dialog_inputs": {},
                "display_name": "Model",
                "dynamic": false,
                "external_options": {},
                "info": "The name of the model to use.",
                "name": "model_name",
                "options": [
                  "gemma-3n-e4b-it",
                  "gemma-3-4b-it",
                  "gemma-3-1b-it",
                  "gemini-robotics-er-1.5-preview",
                  "gemini-flash-lite-latest",
                  "gemini-exp-1206",
                  "gemini-2.5-pro-preview-06-05",
                  "gemini-2.5-pro-preview-03-25",
                  "gemini-2.5-flash-preview-tts",
                  "gemini-2.5-flash-preview-05-20",
                  "gemini-2.5-flash-lite-preview-06-17",
                  "gemini-2.5-flash-image-preview",
                  "gemini-2.5-flash",
                  "gemini-2.0-pro-exp-02-05",
                  "gemini-2.0-flash-thinking-exp-1219",
                  "gemini-2.0-flash-thinking-exp",
                  "gemini-2.0-flash-lite-preview",
                  "gemini-2.0-flash-lite",
                  "gemini-2.0-flash-001"
                ],
                "options_metadata": [],
                "placeholder": "",
                "refresh_button": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "gemini-2.5-pro"
              },
              "n": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "N",
                "dynamic": false,
                "info": "Number of chat completions to generate for each prompt. Note that the API may not return the full n completions if duplicates are generated.",
                "list": false,
                "list_add_label": "Add More",
                "name": "n",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Stream the response from the model. Streaming works only in Chat.",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "System message to pass to the model.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": false,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness. Lower values are more deterministic, higher values are more creative.",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              },
              "tool_model_enabled": {
                "_input_type": "BoolInput",
                "advanced": false,
                "display_name": "Tool Model Enabled",
                "dynamic": false,
                "info": "Whether to use the tool model.",
                "list": false,
                "list_add_label": "Add More",
                "name": "tool_model_enabled",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "top_k": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Top K",
                "dynamic": false,
                "info": "Decode using top-k sampling: consider the set of top_k most probable tokens. Must be positive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_k",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": ""
              },
              "top_p": {
                "_input_type": "FloatInput",
                "advanced": true,
                "display_name": "Top P",
                "dynamic": false,
                "info": "The maximum cumulative probability of tokens to consider when sampling.",
                "list": false,
                "list_add_label": "Add More",
                "name": "top_p",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "float",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "selected_output": "model_output",
          "showNode": true,
          "type": "GoogleGenerativeAIModel"
        },
        "dragging": false,
        "id": "GoogleGenerativeAIModel-2RGCP",
        "measured": {
          "height": 661,
          "width": 320
        },
        "position": {
          "x": -129.1015037216711,
          "y": -639.9693177435264
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "APIRequest-mdLsg",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "data",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Make HTTP requests using URL or cURL commands.",
            "display_name": "API Request",
            "documentation": "https://docs.langflow.org/components-data#api-request",
            "edited": false,
            "field_order": [
              "url_input",
              "curl_input",
              "method",
              "mode",
              "query_params",
              "body",
              "headers",
              "timeout",
              "follow_redirects",
              "save_to_file",
              "include_httpx_metadata"
            ],
            "frozen": false,
            "icon": "Globe",
            "key": "APIRequest",
            "last_updated": "2025-11-07T16:02:55.638Z",
            "legacy": false,
            "lf_version": "1.6.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.007568328950209746,
            "template": {
              "_type": "Component",
              "body": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Body",
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT).",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "body",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Parameter name",
                      "disable_edit": false,
                      "display_name": "Key",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Parameter value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "hidden": false,
                      "name": "value",
                      "sortable": true
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": []
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\nimport re\nimport tempfile\nfrom datetime import datetime, timezone\nfrom pathlib import Path\nfrom typing import Any\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\n\nimport aiofiles\nimport aiofiles.os as aiofiles_os\nimport httpx\nimport validators\n\nfrom langflow.base.curl.parse import parse_context\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import TabInput\nfrom langflow.io import (\n    BoolInput,\n    DataInput,\n    DropdownInput,\n    IntInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n    TableInput,\n)\nfrom langflow.schema.data import Data\nfrom langflow.schema.dotdict import dotdict\nfrom langflow.services.deps import get_settings_service\nfrom langflow.utils.component_utils import set_current_fields, set_field_advanced, set_field_display\n\n# Define fields for each mode\nMODE_FIELDS = {\n    \"URL\": [\n        \"url_input\",\n        \"method\",\n    ],\n    \"cURL\": [\"curl_input\"],\n}\n\n# Fields that should always be visible\nDEFAULT_FIELDS = [\"mode\"]\n\n\nclass APIRequestComponent(Component):\n    display_name = \"API Request\"\n    description = \"Make HTTP requests using URL or cURL commands.\"\n    documentation: str = \"https://docs.langflow.org/components-data#api-request\"\n    icon = \"Globe\"\n    name = \"APIRequest\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"url_input\",\n            display_name=\"URL\",\n            info=\"Enter the URL for the request.\",\n            advanced=False,\n            tool_mode=True,\n        ),\n        MultilineInput(\n            name=\"curl_input\",\n            display_name=\"cURL\",\n            info=(\n                \"Paste a curl command to populate the fields. \"\n                \"This will fill in the dictionary fields for headers and body.\"\n            ),\n            real_time_refresh=True,\n            tool_mode=True,\n            advanced=True,\n            show=False,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Method\",\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\n            value=\"GET\",\n            info=\"The HTTP method to use.\",\n            real_time_refresh=True,\n        ),\n        TabInput(\n            name=\"mode\",\n            display_name=\"Mode\",\n            options=[\"URL\", \"cURL\"],\n            value=\"URL\",\n            info=\"Enable cURL mode to populate fields from a cURL command.\",\n            real_time_refresh=True,\n        ),\n        DataInput(\n            name=\"query_params\",\n            display_name=\"Query Parameters\",\n            info=\"The query parameters to append to the URL.\",\n            advanced=True,\n        ),\n        TableInput(\n            name=\"body\",\n            display_name=\"Body\",\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT).\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Key\",\n                    \"type\": \"str\",\n                    \"description\": \"Parameter name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"description\": \"Parameter value\",\n                },\n            ],\n            value=[],\n            input_types=[\"Data\"],\n            advanced=True,\n            real_time_refresh=True,\n        ),\n        TableInput(\n            name=\"headers\",\n            display_name=\"Headers\",\n            info=\"The headers to send with the request\",\n            table_schema=[\n                {\n                    \"name\": \"key\",\n                    \"display_name\": \"Header\",\n                    \"type\": \"str\",\n                    \"description\": \"Header name\",\n                },\n                {\n                    \"name\": \"value\",\n                    \"display_name\": \"Value\",\n                    \"type\": \"str\",\n                    \"description\": \"Header value\",\n                },\n            ],\n            value=[{\"key\": \"User-Agent\", \"value\": get_settings_service().settings.user_agent}],\n            advanced=True,\n            input_types=[\"Data\"],\n            real_time_refresh=True,\n        ),\n        IntInput(\n            name=\"timeout\",\n            display_name=\"Timeout\",\n            value=30,\n            info=\"The timeout to use for the request.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"follow_redirects\",\n            display_name=\"Follow Redirects\",\n            value=True,\n            info=\"Whether to follow http redirects.\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"save_to_file\",\n            display_name=\"Save to File\",\n            value=False,\n            info=\"Save the API response to a temporary file\",\n            advanced=True,\n        ),\n        BoolInput(\n            name=\"include_httpx_metadata\",\n            display_name=\"Include HTTPx Metadata\",\n            value=False,\n            info=(\n                \"Include properties such as headers, status_code, response_headers, \"\n                \"and redirection_history in the output.\"\n            ),\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"API Response\", name=\"data\", method=\"make_api_request\"),\n    ]\n\n    def _parse_json_value(self, value: Any) -> Any:\n        \"\"\"Parse a value that might be a JSON string.\"\"\"\n        if not isinstance(value, str):\n            return value\n\n        try:\n            parsed = json.loads(value)\n        except json.JSONDecodeError:\n            return value\n        else:\n            return parsed\n\n    def _process_body(self, body: Any) -> dict:\n        \"\"\"Process the body input into a valid dictionary.\"\"\"\n        if body is None:\n            return {}\n        if hasattr(body, \"data\"):\n            body = body.data\n        if isinstance(body, dict):\n            return self._process_dict_body(body)\n        if isinstance(body, str):\n            return self._process_string_body(body)\n        if isinstance(body, list):\n            return self._process_list_body(body)\n        return {}\n\n    def _process_dict_body(self, body: dict) -> dict:\n        \"\"\"Process dictionary body by parsing JSON values.\"\"\"\n        return {k: self._parse_json_value(v) for k, v in body.items()}\n\n    def _process_string_body(self, body: str) -> dict:\n        \"\"\"Process string body by attempting JSON parse.\"\"\"\n        try:\n            return self._process_body(json.loads(body))\n        except json.JSONDecodeError:\n            return {\"data\": body}\n\n    def _process_list_body(self, body: list) -> dict:\n        \"\"\"Process list body by converting to key-value dictionary.\"\"\"\n        processed_dict = {}\n        try:\n            for item in body:\n                # Unwrap Data objects\n                current_item = item\n                if hasattr(item, \"data\"):\n                    unwrapped_data = item.data\n                    # If the unwrapped data is a dict but not key-value format, use it directly\n                    if isinstance(unwrapped_data, dict) and not self._is_valid_key_value_item(unwrapped_data):\n                        return unwrapped_data\n                    current_item = unwrapped_data\n                if not self._is_valid_key_value_item(current_item):\n                    continue\n                key = current_item[\"key\"]\n                value = self._parse_json_value(current_item[\"value\"])\n                processed_dict[key] = value\n        except (KeyError, TypeError, ValueError) as e:\n            self.log(f\"Failed to process body list: {e}\")\n            return {}\n        return processed_dict\n\n    def _is_valid_key_value_item(self, item: Any) -> bool:\n        \"\"\"Check if an item is a valid key-value dictionary.\"\"\"\n        return isinstance(item, dict) and \"key\" in item and \"value\" in item\n\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\n        \"\"\"Parse a cURL command and update build configuration.\"\"\"\n        try:\n            parsed = parse_context(curl)\n\n            # Update basic configuration\n            url = parsed.url\n            # Normalize URL before setting it\n            url = self._normalize_url(url)\n\n            build_config[\"url_input\"][\"value\"] = url\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\n\n            # Process headers\n            headers_list = [{\"key\": k, \"value\": v} for k, v in parsed.headers.items()]\n            build_config[\"headers\"][\"value\"] = headers_list\n\n            # Process body data\n            if not parsed.data:\n                build_config[\"body\"][\"value\"] = []\n            elif parsed.data:\n                try:\n                    json_data = json.loads(parsed.data)\n                    if isinstance(json_data, dict):\n                        body_list = [\n                            {\"key\": k, \"value\": json.dumps(v) if isinstance(v, dict | list) else str(v)}\n                            for k, v in json_data.items()\n                        ]\n                        build_config[\"body\"][\"value\"] = body_list\n                    else:\n                        build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": json.dumps(json_data)}]\n                except json.JSONDecodeError:\n                    build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": parsed.data}]\n\n        except Exception as exc:\n            msg = f\"Error parsing curl: {exc}\"\n            self.log(msg)\n            raise ValueError(msg) from exc\n\n        return build_config\n\n    def _normalize_url(self, url: str) -> str:\n        \"\"\"Normalize URL by adding https:// if no protocol is specified.\"\"\"\n        if not url or not isinstance(url, str):\n            msg = \"URL cannot be empty\"\n            raise ValueError(msg)\n\n        url = url.strip()\n        if url.startswith((\"http://\", \"https://\")):\n            return url\n        return f\"https://{url}\"\n\n    async def make_request(\n        self,\n        client: httpx.AsyncClient,\n        method: str,\n        url: str,\n        headers: dict | None = None,\n        body: Any = None,\n        timeout: int = 5,\n        *,\n        follow_redirects: bool = True,\n        save_to_file: bool = False,\n        include_httpx_metadata: bool = False,\n    ) -> Data:\n        method = method.upper()\n        if method not in {\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"}:\n            msg = f\"Unsupported method: {method}\"\n            raise ValueError(msg)\n\n        processed_body = self._process_body(body)\n        redirection_history = []\n\n        try:\n            # Prepare request parameters\n            request_params = {\n                \"method\": method,\n                \"url\": url,\n                \"headers\": headers,\n                \"json\": processed_body,\n                \"timeout\": timeout,\n                \"follow_redirects\": follow_redirects,\n            }\n            response = await client.request(**request_params)\n\n            redirection_history = [\n                {\n                    \"url\": redirect.headers.get(\"Location\", str(redirect.url)),\n                    \"status_code\": redirect.status_code,\n                }\n                for redirect in response.history\n            ]\n\n            is_binary, file_path = await self._response_info(response, with_file_path=save_to_file)\n            response_headers = self._headers_to_dict(response.headers)\n\n            # Base metadata\n            metadata = {\n                \"source\": url,\n                \"status_code\": response.status_code,\n                \"response_headers\": response_headers,\n            }\n\n            if redirection_history:\n                metadata[\"redirection_history\"] = redirection_history\n\n            if save_to_file:\n                mode = \"wb\" if is_binary else \"w\"\n                encoding = response.encoding if mode == \"w\" else None\n                if file_path:\n                    await aiofiles_os.makedirs(file_path.parent, exist_ok=True)\n                    if is_binary:\n                        async with aiofiles.open(file_path, \"wb\") as f:\n                            await f.write(response.content)\n                            await f.flush()\n                    else:\n                        async with aiofiles.open(file_path, \"w\", encoding=encoding) as f:\n                            await f.write(response.text)\n                            await f.flush()\n                    metadata[\"file_path\"] = str(file_path)\n\n                if include_httpx_metadata:\n                    metadata.update({\"headers\": headers})\n                return Data(data=metadata)\n\n            # Handle response content\n            if is_binary:\n                result = response.content\n            else:\n                try:\n                    result = response.json()\n                except json.JSONDecodeError:\n                    self.log(\"Failed to decode JSON response\")\n                    result = response.text.encode(\"utf-8\")\n\n            metadata[\"result\"] = result\n\n            if include_httpx_metadata:\n                metadata.update({\"headers\": headers})\n\n            return Data(data=metadata)\n        except (httpx.HTTPError, httpx.RequestError, httpx.TimeoutException) as exc:\n            self.log(f\"Error making request to {url}\")\n            return Data(\n                data={\n                    \"source\": url,\n                    \"headers\": headers,\n                    \"status_code\": 500,\n                    \"error\": str(exc),\n                    **({\"redirection_history\": redirection_history} if redirection_history else {}),\n                },\n            )\n\n    def add_query_params(self, url: str, params: dict) -> str:\n        \"\"\"Add query parameters to URL efficiently.\"\"\"\n        if not params:\n            return url\n        url_parts = list(urlparse(url))\n        query = dict(parse_qsl(url_parts[4]))\n        query.update(params)\n        url_parts[4] = urlencode(query)\n        return urlunparse(url_parts)\n\n    def _headers_to_dict(self, headers: httpx.Headers) -> dict[str, str]:\n        \"\"\"Convert HTTP headers to a dictionary with lowercased keys.\"\"\"\n        return {k.lower(): v for k, v in headers.items()}\n\n    def _process_headers(self, headers: Any) -> dict:\n        \"\"\"Process the headers input into a valid dictionary.\"\"\"\n        if headers is None:\n            return {}\n        if isinstance(headers, dict):\n            return headers\n        if isinstance(headers, list):\n            return {item[\"key\"]: item[\"value\"] for item in headers if self._is_valid_key_value_item(item)}\n        return {}\n\n    async def make_api_request(self) -> Data:\n        \"\"\"Make HTTP request with optimized parameter handling.\"\"\"\n        method = self.method\n        url = self.url_input.strip() if isinstance(self.url_input, str) else \"\"\n        headers = self.headers or {}\n        body = self.body or {}\n        timeout = self.timeout\n        follow_redirects = self.follow_redirects\n        save_to_file = self.save_to_file\n        include_httpx_metadata = self.include_httpx_metadata\n\n        # if self.mode == \"cURL\" and self.curl_input:\n        #     self._build_config = self.parse_curl(self.curl_input, dotdict())\n        #     # After parsing curl, get the normalized URL\n        #     url = self._build_config[\"url_input\"][\"value\"]\n\n        # Normalize URL before validation\n        url = self._normalize_url(url)\n\n        # Validate URL\n        if not validators.url(url):\n            msg = f\"Invalid URL provided: {url}\"\n            raise ValueError(msg)\n\n        # Process query parameters\n        if isinstance(self.query_params, str):\n            query_params = dict(parse_qsl(self.query_params))\n        else:\n            query_params = self.query_params.data if self.query_params else {}\n\n        # Process headers and body\n        headers = self._process_headers(headers)\n        body = self._process_body(body)\n        url = self.add_query_params(url, query_params)\n\n        async with httpx.AsyncClient() as client:\n            result = await self.make_request(\n                client,\n                method,\n                url,\n                headers,\n                body,\n                timeout,\n                follow_redirects=follow_redirects,\n                save_to_file=save_to_file,\n                include_httpx_metadata=include_httpx_metadata,\n            )\n        self.status = result\n        return result\n\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\n        \"\"\"Update the build config based on the selected mode.\"\"\"\n        if field_name != \"mode\":\n            if field_name == \"curl_input\" and self.mode == \"cURL\" and self.curl_input:\n                return self.parse_curl(self.curl_input, build_config)\n            return build_config\n\n        # print(f\"Current mode: {field_value}\")\n        if field_value == \"cURL\":\n            set_field_display(build_config, \"curl_input\", value=True)\n            if build_config[\"curl_input\"][\"value\"]:\n                build_config = self.parse_curl(build_config[\"curl_input\"][\"value\"], build_config)\n        else:\n            set_field_display(build_config, \"curl_input\", value=False)\n\n        return set_current_fields(\n            build_config=build_config,\n            action_fields=MODE_FIELDS,\n            selected_action=field_value,\n            default_fields=DEFAULT_FIELDS,\n            func=set_field_advanced,\n            default_value=True,\n        )\n\n    async def _response_info(\n        self, response: httpx.Response, *, with_file_path: bool = False\n    ) -> tuple[bool, Path | None]:\n        \"\"\"Determine the file path and whether the response content is binary.\n\n        Args:\n            response (Response): The HTTP response object.\n            with_file_path (bool): Whether to save the response content to a file.\n\n        Returns:\n            Tuple[bool, Path | None]:\n                A tuple containing a boolean indicating if the content is binary and the full file path (if applicable).\n        \"\"\"\n        content_type = response.headers.get(\"Content-Type\", \"\")\n        is_binary = \"application/octet-stream\" in content_type or \"application/binary\" in content_type\n\n        if not with_file_path:\n            return is_binary, None\n\n        component_temp_dir = Path(tempfile.gettempdir()) / self.__class__.__name__\n\n        # Create directory asynchronously\n        await aiofiles_os.makedirs(component_temp_dir, exist_ok=True)\n\n        filename = None\n        if \"Content-Disposition\" in response.headers:\n            content_disposition = response.headers[\"Content-Disposition\"]\n            filename_match = re.search(r'filename=\"(.+?)\"', content_disposition)\n            if filename_match:\n                extracted_filename = filename_match.group(1)\n                filename = extracted_filename\n\n        # Step 3: Infer file extension or use part of the request URL if no filename\n        if not filename:\n            # Extract the last segment of the URL path\n            url_path = urlparse(str(response.request.url) if response.request else \"\").path\n            base_name = Path(url_path).name  # Get the last segment of the path\n            if not base_name:  # If the path ends with a slash or is empty\n                base_name = \"response\"\n\n            # Infer file extension\n            content_type_to_extension = {\n                \"text/plain\": \".txt\",\n                \"application/json\": \".json\",\n                \"image/jpeg\": \".jpg\",\n                \"image/png\": \".png\",\n                \"application/octet-stream\": \".bin\",\n            }\n            extension = content_type_to_extension.get(content_type, \".bin\" if is_binary else \".txt\")\n            filename = f\"{base_name}{extension}\"\n\n        # Step 4: Define the full file path\n        file_path = component_temp_dir / filename\n\n        # Step 5: Check if file exists asynchronously and handle accordingly\n        try:\n            # Try to create the file exclusively (x mode) to check existence\n            async with aiofiles.open(file_path, \"x\") as _:\n                pass  # File created successfully, we can use this path\n        except FileExistsError:\n            # If file exists, append a timestamp to the filename\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S%f\")\n            file_path = component_temp_dir / f\"{timestamp}-{filename}\"\n\n        return is_binary, file_path\n"
              },
              "curl_input": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "cURL",
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "curl_input",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "follow_redirects": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Follow Redirects",
                "dynamic": false,
                "info": "Whether to follow http redirects.",
                "list": false,
                "list_add_label": "Add More",
                "name": "follow_redirects",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "headers": {
                "_input_type": "TableInput",
                "advanced": true,
                "display_name": "Headers",
                "dynamic": false,
                "info": "The headers to send with the request",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "name": "headers",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Header name",
                      "disable_edit": false,
                      "display_name": "Header",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Header value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "value",
                      "sortable": true,
                      "type": "str"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "User-Agent",
                    "value": "langflow"
                  }
                ]
              },
              "include_httpx_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include HTTPx Metadata",
                "dynamic": false,
                "info": "Include properties such as headers, status_code, response_headers, and redirection_history in the output.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_httpx_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "method": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Method",
                "dynamic": false,
                "external_options": {},
                "info": "The HTTP method to use.",
                "name": "method",
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "GET"
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Enable cURL mode to populate fields from a cURL command.",
                "name": "mode",
                "options": [
                  "URL",
                  "cURL"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "URL"
              },
              "query_params": {
                "_input_type": "DataInput",
                "advanced": true,
                "display_name": "Query Parameters",
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "query_params",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "save_to_file": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Save to File",
                "dynamic": false,
                "info": "Save the API response to a temporary file",
                "list": false,
                "list_add_label": "Add More",
                "name": "save_to_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 30
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "curl_input": {
                        "default": "",
                        "description": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                        "title": "Curl Input",
                        "type": "string"
                      },
                      "url_input": {
                        "default": "",
                        "description": "Enter the URL for the request.",
                        "title": "Url Input",
                        "type": "string"
                      }
                    },
                    "description": "Make HTTP requests using URL or cURL commands.",
                    "display_description": "Make HTTP requests using URL or cURL commands.",
                    "display_name": "make_api_request",
                    "name": "make_api_request",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "make_api_request"
                    ]
                  }
                ]
              },
              "url_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "Enter the URL for the request.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "url_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "APIRequest"
        },
        "dragging": false,
        "id": "APIRequest-mdLsg",
        "measured": {
          "height": 379,
          "width": 320
        },
        "position": {
          "x": -662.528828669159,
          "y": 37.754431263336954
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "DuckDuckGoSearchComponent-AjgK2",
          "node": {
            "base_classes": [
              "DataFrame"
            ],
            "beta": false,
            "category": "duckduckgo",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Search the web using DuckDuckGo with customizable result limits",
            "display_name": "DuckDuckGo Search",
            "documentation": "https://python.langchain.com/docs/integrations/tools/ddg",
            "edited": false,
            "field_order": [
              "input_value",
              "max_results",
              "max_snippet_length"
            ],
            "frozen": false,
            "icon": "DuckDuckGo",
            "key": "DuckDuckGoSearchComponent",
            "last_updated": "2025-11-07T16:02:55.639Z",
            "legacy": false,
            "lf_version": "1.6.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Toolset",
                "group_outputs": false,
                "hidden": null,
                "method": "to_toolkit",
                "name": "component_as_tool",
                "options": null,
                "required_inputs": null,
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.4794946481224883,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langchain_community.tools import DuckDuckGoSearchRun\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import IntInput, MessageTextInput\nfrom langflow.schema.data import Data\nfrom langflow.schema.dataframe import DataFrame\nfrom langflow.template.field.base import Output\n\n\nclass DuckDuckGoSearchComponent(Component):\n    \"\"\"Component for performing web searches using DuckDuckGo.\"\"\"\n\n    display_name = \"DuckDuckGo Search\"\n    description = \"Search the web using DuckDuckGo with customizable result limits\"\n    documentation = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon = \"DuckDuckGo\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n            info=\"The search query to execute with DuckDuckGo\",\n            tool_mode=True,\n        ),\n        IntInput(\n            name=\"max_results\",\n            display_name=\"Max Results\",\n            value=5,\n            required=False,\n            advanced=True,\n            info=\"Maximum number of search results to return\",\n        ),\n        IntInput(\n            name=\"max_snippet_length\",\n            display_name=\"Max Snippet Length\",\n            value=100,\n            required=False,\n            advanced=True,\n            info=\"Maximum length of each result snippet\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"DataFrame\", name=\"dataframe\", method=\"fetch_content_dataframe\"),\n    ]\n\n    def _build_wrapper(self) -> DuckDuckGoSearchRun:\n        \"\"\"Build the DuckDuckGo search wrapper.\"\"\"\n        return DuckDuckGoSearchRun()\n\n    def run_model(self) -> DataFrame:\n        return self.fetch_content_dataframe()\n\n    def fetch_content(self) -> list[Data]:\n        \"\"\"Execute the search and return results as Data objects.\"\"\"\n        try:\n            wrapper = self._build_wrapper()\n\n            full_results = wrapper.run(f\"{self.input_value} (site:*)\")\n\n            result_list = full_results.split(\"\\n\")[: self.max_results]\n\n            data_results = []\n            for result in result_list:\n                if result.strip():\n                    snippet = result[: self.max_snippet_length]\n                    data_results.append(\n                        Data(\n                            text=snippet,\n                            data={\n                                \"content\": result,\n                                \"snippet\": snippet,\n                            },\n                        )\n                    )\n        except (ValueError, AttributeError) as e:\n            error_data = [Data(text=str(e), data={\"error\": str(e)})]\n            self.status = error_data\n            return error_data\n        else:\n            self.status = data_results\n            return data_results\n\n    def fetch_content_dataframe(self) -> DataFrame:\n        \"\"\"Convert the search results to a DataFrame.\n\n        Returns:\n            DataFrame: A DataFrame containing the search results.\n        \"\"\"\n        data = self.fetch_content()\n        return DataFrame(data)\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Search Query",
                "dynamic": false,
                "info": "The search query to execute with DuckDuckGo",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "max_results": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Results",
                "dynamic": false,
                "info": "Maximum number of search results to return",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_results",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 5
              },
              "max_snippet_length": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Snippet Length",
                "dynamic": false,
                "info": "Maximum length of each result snippet",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_snippet_length",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 100
              },
              "tools_metadata": {
                "_input_type": "ToolsInput",
                "advanced": false,
                "display_name": "Actions",
                "dynamic": false,
                "info": "Modify tool names and descriptions to help agents understand when to use each tool.",
                "is_list": true,
                "list_add_label": "Add More",
                "name": "tools_metadata",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tools",
                "value": [
                  {
                    "args": {
                      "input_value": {
                        "description": "The search query to execute with DuckDuckGo",
                        "title": "Input Value",
                        "type": "string"
                      }
                    },
                    "description": "Search the web using DuckDuckGo with customizable result limits",
                    "display_description": "Search the web using DuckDuckGo with customizable result limits",
                    "display_name": "fetch_content_dataframe",
                    "name": "fetch_content_dataframe",
                    "readonly": false,
                    "status": true,
                    "tags": [
                      "fetch_content_dataframe"
                    ]
                  }
                ]
              }
            },
            "tool_mode": true
          },
          "showNode": true,
          "type": "DuckDuckGoSearchComponent"
        },
        "dragging": false,
        "id": "DuckDuckGoSearchComponent-AjgK2",
        "measured": {
          "height": 217,
          "width": 320
        },
        "position": {
          "x": -672.4290436329397,
          "y": 507.8249882171383
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-hDEjR",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Text Output",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.6.5",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-hDEjR",
        "measured": {
          "height": 203,
          "width": 320
        },
        "position": {
          "x": 995.6700199241186,
          "y": 468.3565231328921
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-CXSsy",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Text Input",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-CXSsy",
        "measured": {
          "height": 203,
          "width": 320
        },
        "position": {
          "x": -54.37494432583644,
          "y": 577.9926361616999
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "WorkspaceToolsAll-lvXOD",
          "node": {
            "base_classes": [
              "Tool"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Returns all workspace tools: read_file, write_file, list_directory, shell_command",
            "display_name": "Workspace Tools (All)",
            "documentation": "",
            "edited": false,
            "field_order": [],
            "frozen": false,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "All Tools",
                "group_outputs": false,
                "method": "build_all_tools",
                "name": "tools_list",
                "selected": "Tool",
                "tool_mode": true,
                "types": [
                  "Tool"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "\"\"\"Initialized tools - returns all tools as a list.\"\"\"\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.io import Output\nfrom langchain_core.tools import StructuredTool\nfrom pydantic import BaseModel, Field\nimport subprocess\nimport os\nfrom pathlib import Path\n\nWORKSPACE_ROOT = Path(\"/app/workspace\")\n\ndef inside_root(p: Path) -> bool:\n    \"\"\"Check path traversal.\"\"\"\n    try:\n        return p.resolve().is_relative_to(WORKSPACE_ROOT.resolve())\n    except:\n        return False\n\n# Input schemas\nclass ReadFileInput(BaseModel):\n    path: str = Field(description=\"File path relative to workspace\")\n\nclass WriteFileInput(BaseModel):\n    path: str = Field(description=\"File path relative to workspace\")\n    content: str = Field(description=\"Content to write to the file\")\n\nclass ListDirInput(BaseModel):\n    path: str = Field(default=\".\", description=\"Directory path relative to workspace (default: current directory)\")\n\nclass ShellCommandInput(BaseModel):\n    command: str = Field(description=\"Shell command to execute (allowed: ls, cat, git, python, pytest, ruff, node, npm, rg, pip)\")\n\n# Tool functions\ndef read_file_func(path: str) -> str:\n    try:\n        full_path = (WORKSPACE_ROOT / path).resolve()\n        if not inside_root(full_path):\n            return f\"Error: Path outside workspace: {path}\"\n        if not full_path.exists():\n            return f\"Error: File not found: {path}\"\n        with open(full_path, 'r', encoding='utf-8') as f:\n            content = f.read()\n        return f\"File: {path}\\n\\n{content}\"\n    except Exception as e:\n        return f\"Error reading {path}: {str(e)}\"\n\ndef write_file_func(path: str, content: str) -> str:\n    try:\n        full_path = (WORKSPACE_ROOT / path).resolve()\n        if not inside_root(full_path):\n            return f\"Error: Path outside workspace: {path}\"\n        full_path.parent.mkdir(parents=True, exist_ok=True)\n        with open(full_path, 'w', encoding='utf-8') as f:\n            f.write(content)\n        return f\"Successfully wrote {len(content)} characters to {path}\"\n    except Exception as e:\n        return f\"Error writing {path}: {str(e)}\"\n\ndef list_directory_func(path: str = \".\") -> str:\n    try:\n        full_path = (WORKSPACE_ROOT / path).resolve()\n        if not inside_root(full_path):\n            return f\"Error: Path outside workspace: {path}\"\n        if not full_path.exists():\n            return f\"Error: Directory not found: {path}\"\n        if not full_path.is_dir():\n            return f\"Error: Not a directory: {path}\"\n        \n        items = []\n        for item in sorted(full_path.iterdir()):\n            rel_path = item.relative_to(WORKSPACE_ROOT)\n            if item.is_dir():\n                items.append(f\"[DIR]  {rel_path}/\")\n            else:\n                size = item.stat().st_size\n                items.append(f\"[FILE] {rel_path} ({size} bytes)\")\n        \n        return f\"Contents of {path}:\\n\" + \"\\n\".join(items) if items else f\"Empty directory: {path}\"\n    except Exception as e:\n        return f\"Error listing {path}: {str(e)}\"\n\n# Get allowed commands from environment or use defaults\nALLOWED_COMMANDS = os.getenv('ALLOWED_SHELL_COMMANDS', 'ls,cat,git,python,pytest,ruff,node,npm,rg,pip').split(',')\n\ndef shell_command_func(command: str) -> str:\n    cmd_parts = command.strip().split()\n    if not cmd_parts or cmd_parts[0] not in ALLOWED_COMMANDS:\n        return f\"Error: Command not allowed. Allowed: {', '.join(ALLOWED_COMMANDS)}\"\n    \n    try:\n        result = subprocess.run(\n            command,\n            shell=True,\n            cwd=str(WORKSPACE_ROOT),\n            capture_output=True,\n            text=True,\n            timeout=25\n        )\n        output = result.stdout + result.stderr\n        if len(output) > 8000:\n            output = output[:8000] + \"\\n... (truncated)\"\n        return f\"Command: {command}\\nExit code: {result.returncode}\\n\\n{output}\"\n    except subprocess.TimeoutExpired:\n        return f\"Error: Command timed out after 25s: {command}\"\n    except Exception as e:\n        return f\"Error executing {command}: {str(e)}\"\n\n\nclass WorkspaceTools(LCToolComponent):\n    display_name = \"Workspace Tools (All)\"\n    description = \"Returns all workspace tools: read_file, write_file, list_directory, shell_command\"\n    name = \"WorkspaceToolsAll\"\n    \n    outputs = [\n        Output(name=\"tools_list\", display_name=\"All Tools\", method=\"build_all_tools\")\n    ]\n    \n    def build_config(self):\n        return {}\n    \n    def build_all_tools(self) -> list[Tool]:\n        \"\"\"Return all 4 tools as a list.\"\"\"\n        \n        read_tool = StructuredTool(\n            name=\"read_file\",\n            description=\"Read a UTF-8 text file from the workspace. Use this to read existing code or data files. Input should be the file path relative to workspace root.\",\n            func=read_file_func,\n            args_schema=ReadFileInput\n        )\n        \n        write_tool = StructuredTool(\n            name=\"write_file\",\n            description=\"Write UTF-8 text to a file in the workspace. Creates directories if needed. Use this to create new files or overwrite existing ones. Inputs: path (relative to workspace) and content (the text to write).\",\n            func=write_file_func,\n            args_schema=WriteFileInput\n        )\n        \n        list_tool = StructuredTool(\n            name=\"list_directory\",\n            description=\"List files and directories in the workspace. Use this to explore the file structure. Input should be directory path relative to workspace (default: current directory).\",\n            func=list_directory_func,\n            args_schema=ListDirInput\n        )\n        \n        shell_tool = StructuredTool(\n            name=\"shell_command\",\n            description=f\"Run shell commands in the workspace. Allowed commands: {', '.join(ALLOWED_COMMANDS)}. Use this to run code, install packages, or execute tests. Input should be the shell command string.\",\n            func=shell_command_func,\n            args_schema=ShellCommandInput\n        )\n        \n        return [read_tool, write_tool, list_tool, shell_tool]\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "WorkspaceToolsAll"
        },
        "dragging": false,
        "id": "WorkspaceToolsAll-lvXOD",
        "measured": {
          "height": 137,
          "width": 320
        },
        "position": {
          "x": -685.9260439826281,
          "y": -295.2690709805567
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": 463.5455819710699,
      "y": 343.85973227324894,
      "zoom": 0.4841790437169491
    }
  },
  "description": "gem agent best",
  "endpoint_name": null,
  "id": "83a553b5-e241-40db-86c7-0fba41818ae8",
  "is_component": false,
  "last_tested_version": "1.6.5",
  "name": "gemini_agent_v2",
  "tags": []
}